# Deck Validation Report

**Deck**: 
**Target VC**: Earlybird Capital
**Validated**: 2026-02-26T23:54:18.862393
**Overall Score**: 88/100 — **PASS** (threshold: 60)

---

## Score Breakdown

| Dimension | Score | Weight | Weighted |
|-----------|-------|--------|----------|
| Completeness | 100/100 | 25% | 25.0 |
| Metrics Density | 100/100 | 20% | 20.0 |
| Narrative Coherence | 78/100 | 20% | 15.6 |
| Thesis Alignment | 82/100 | 20% | 16.4 |
| Common Mistakes | 74/100 | 15% | 11.1 |
| **TOTAL** | | | **88.1** |

### Completeness

**Score**: 100/100
**Rationale**: Deck has 15 slides (15 with speaker notes). 1 gaps found.

**Evidence Found:**
- 15/15 slides present
- Required slide types present: ai-architecture, business-model, competitive-landscape, cover, executive-summary, financials, go-to-market, market-sizing, problem, product, solution, team, the-ask, traction, why-now
- Speaker notes on 15/15 slides

**Evidence Missing:**
- 10 data gaps identified: Exact NDR figure from consulting business not available — used qualitative proxy, Exact monthly burn rate not confirmed — used EUR 80-100K framing from updates doc, Number of repeat customers among named logos (Eventos, Falkensteg, Kalkül, Primus, Valor) not specified — used 100% consulting-to-platform conversion framing, Gross margin on consulting revenue not confirmed — used 30% from updates doc, CAC figure not available — deck notes this is pre-product-sales stage

### Metrics Density

**Score**: 100/100
**Rationale**: 44 metrics found (~29 expected from templates). 7/8 VC emphasis metrics addressed.

**Evidence Found:**
- 44 metrics across deck
- Found: ARR and YoY growth rate
- Found: Gross margin trajectory
- Found: Burn multiple (new ARR / cash burned)
- Found: Capital efficiency ratio (revenue / total raised)
- Found: Customer count and logo quality
- Found: ACV and expansion revenue
- Found: Bottom-up SOM with methodology

**Evidence Missing:**
- Missing: Net Dollar Retention (NDR)

### Narrative Coherence

**Score**: 78/100
**Rationale**: The deck follows a disciplined investor psychology arc: the cover hooks with practitioner credibility and bootstrapped revenue, the problem slide builds tension with quantified failure rates, the solution resolves it with measured outcomes, traction provides proof, team builds trust, and the ask is specific and milestone-anchored. Transitions between slides are explicit and purposeful — each slide ends with a forward bridge that maintains momentum. The 'consulting-to-platform' thread is woven consistently throughout, which is the deck's strongest narrative device. Minor deductions: the AI architecture slide (15) placed after the ask (14) disrupts the closing momentum — it reads as an appendix but is positioned as a primary slide, creating a structural anti-climax. The executive summary (slide 2) front-loads too much detail that is better revealed progressively, slightly diluting the hook-tension dynamic. The 'why now' slide (4) is strong but the EU AI Act urgency could be more viscerally connected to the customer pain established in slide 3.

**Evidence Found:**
- Explicit transition sentences on every slide maintain forward momentum
- Consulting-to-platform conversion narrative is consistent from slide 2 through slide 10
- Hook-Tension-Resolution arc: cover (hook) → problem 86%/23% gap (tension) → 6-week deployment solution (resolution) → EUR 2M bootstrapped (proof) → Google advisors (trust) → EUR 3M ask (close)
- Problem framing in slide 3 uses a single memorable statistic (63pp gap) as the anchor
- Financial slide (13) reframes the ask before the ask slide — smart sequencing
- Speaker notes reinforce narrative discipline with specific opening lines per slide

**Evidence Missing:**
- AI architecture slide (15) placed after the ask disrupts closing momentum — should be appendix or repositioned before the ask
- Executive summary (slide 2) pre-empts too much of the progressive reveal, reducing tension in subsequent slides
- No single customer story or mini case study to make the problem/solution arc emotionally concrete — all evidence is aggregate
- Why-now slide (4) does not explicitly connect EU AI Act urgency back to the named customer logos, missing a personalization opportunity
- The transition from competitive landscape (11) to team (12) is the weakest link — no explicit bridge explaining why this team wins this specific competitive battle

### Thesis Alignment

**Score**: 82/100
**Rationale**: The deck addresses all seven Earlybird thesis points with varying depth. European sovereignty is present but somewhat implicit — it appears as a feature (cloud-agnostic, on-premise, GDPR) rather than a strategic identity. Category creation is strongly framed ('Agent OS') with explicit analogies to SAP and Stripe. Capital efficiency is the deck's single strongest thesis alignment — EUR 2M bootstrapped with near-zero burn multiple is exceptional evidence. AI as infrastructure is architecturally demonstrated through the 7-layer stack. Deep tech commercialization is proven by 25+ deployments. Global winner potential is mapped but the pathway from DACH to global feels optimistic given current team size. Domain expertise is credibly established through the PwC/Allianz founding story. The one notable gap is that European sovereignty is not positioned as a competitive differentiator in the competitive landscape slide — it should be a named axis given Earlybird's portfolio thesis around Aleph Alpha.

**Evidence Found:**
- Thesis 1 (European sovereignty): Cloud-agnostic, on-premise deployment, GDPR-native PII detection, EU AI Act compliance layer — present in slides 4, 6, 15
- Thesis 2 (Category creation): 'Agent OS' framing, SAP/Stripe analogies, empty top-right quadrant in competitive 2x2 — slides 1, 5, 11
- Thesis 3 (Capital efficiency): EUR 2M revenue, zero raised, burn multiple ~0, consulting-as-CAC model — slides 2, 9, 13
- Thesis 4 (AI as infrastructure): 7-layer stack with proprietary L4-L7 moat, N+M connector architecture, 3D Policy Model — slides 6, 15
- Thesis 5 (Deep tech commercialization): 25+ production deployments, TRL 4 confirmed, ZIM grant validation — slides 2, 9, 14
- Thesis 6 (Global winner potential): DACH → EU-27 → global marketplace pathway, Google Cloud CEE advisory — slides 7, 10, 12
- Thesis 7 (Domain expertise): PwC M&A/AI strategy + Allianz transformation pedigree, 25 deployments as domain proof — slide 12

**Evidence Missing:**
- Thesis 1 (European sovereignty): Not positioned as a named competitive axis in the competitive landscape slide — a missed opportunity given Earlybird's Aleph Alpha investment and sovereignty thesis
- Thesis 6 (Global winner potential): Team of 4-5 engineers executing DACH + EU-27 + global marketplace simultaneously is not credibly staffed — the global ambition outpaces the current organizational capacity shown
- Thesis 3 (Capital efficiency): No explicit burn multiple calculation shown as a formula — the ~0 claim is made but not derived transparently for a skeptical investor
- Thesis 4 (Proprietary data moat): The data moat from 25+ deployments (training data, domain-specific patterns) is not explicitly articulated — this is a significant missed opportunity to claim a data flywheel

### Common Mistakes

**Score**: 74/100
**Rationale**: The deck avoids most common pitfalls with notable discipline. AI commoditization is proactively addressed in the competitive slide with the 'tailwind not headwind' framing. Bottom-up SOM is explicitly methodologized. Customer ROI is quantified (60% → <30% infrastructure cost, EUR 45-75K saved per project). Use of funds is broken down with percentages. However, the deck over-indexes on architectural detail — slide 15 is a full technical deep-dive that belongs in a data room appendix, not as the closing primary slide. NDR is absent as a hard metric, replaced by a qualitative proxy that a sophisticated VC will notice. The competitive positioning is strong on the two named axes but does not address the emerging threat from hyperscaler-native agent orchestration (AWS Bedrock Agents, Azure AI Foundry) which are moving rapidly into the mid-market. The title/headline quality is consistently strong and data-driven throughout — a genuine strength.

**Evidence Found:**
- AI commoditization proactively addressed: 'Commoditization is our tailwind, not our risk' framing in slide 11
- Bottom-up SOM with explicit methodology: 70,000 companies × 45% adoption × EUR 24-60K ACV = EUR 1.5B — slide 7
- Quantified customer ROI: infrastructure cost 60% → <30%, EUR 45-75K saved per project, 3-6 months → <6 weeks — slide 5
- Use of funds breakdown with percentages: 60% engineering, 20% GTM, 12% ZIM, 8% ops — slide 14
- Competitive positioning uses differentiated axes (completeness vs. accessibility) rather than generic feature matrix — slide 11
- Titles and headlines are consistently specific and data-driven throughout all 15 slides
- NDR gap is transparently acknowledged with a proxy methodology rather than silently omitted

**Evidence Missing:**
- Over-indexing on architecture: Slide 15 is a full technical deep-dive positioned as a primary closing slide — should be appendix material, disrupts the business narrative close
- Hard NDR metric absent: The qualitative proxy ('100% of pilots from existing clients') is not a substitute for a retention rate — sophisticated investors will flag this gap
- Hyperscaler threat not addressed: AWS Bedrock Agents, Azure AI Foundry, and Google Vertex AI Agent Builder are moving into mid-market orchestration — their absence from the competitive analysis is a credibility gap
- YoY revenue growth rate not explicitly stated as a headline metric — implied but not calculated (Year 1 baseline unknown, making Year 2 EUR 2M growth rate unverifiable)
- LTV/CAC ratio absent — even an estimated range would strengthen the unit economics story given the land-and-expand model described

---

## VC-Specific Checks

| Check | Status | Evidence |
|-------|--------|----------|
| European sovereignty angle must be present | PASS | Keywords found: sovereign, european, europe, data sovereignty |
| Bottom-up market sizing required (not just top-down TAM) | PASS | Keywords found: bottom-up, som |
| Capital efficiency must be explicitly highlighted | PASS | Keywords found: capital efficien, burn multiple, revenue-to-raised, capital-efficient |
| Named or anonymized customer evidence with quantified ROI | PASS | Keywords found: customer, pilot, roi, evidence |
| AI commoditization risk must be proactively addressed | PASS | Keywords found: commodit, moat, defensib, proprietary |
| Gross margin trajectory must be shown or discussed | PASS | Keywords found: gross margin, margin trajectory |
| Category creation narrative should be present | PASS | Keywords found: category, category creation |

---

## Per-Slide Scores

### Slide 1: cover — 100/100

**Suggestions:**
- Strong cover — 'Agent OS' category framing is memorable and the EUR 2M bootstrapped metric creates immediate credibility. Minor issue: company name inconsistency ('Neurawork' in speaker notes vs. 'NeuraPlox' as product name) could create confusion about what is the company vs. the product. Clarify the brand architecture.

### Slide 2: executive-summary — 100/100

**Suggestions:**
- Executive summary is information-dense and accurate but front-loads too much of the progressive reveal. The EUR 2M ARR equivalent label is technically imprecise — consulting/services revenue is not ARR. This distinction will be immediately challenged by a VC; label it 'EUR 2M+ revenue' or 'EUR 2M+ services revenue' to avoid a credibility hit on the first substantive slide.

### Slide 3: problem — 100/100

**Suggestions:**
- Best problem slide in the deck. The N×M trap is a genuinely memorable framing device. The 63pp gap (86% intent vs. 23% execution) is a powerful anchor statistic. Third-party citations (maximal.digital, Bitkom) add credibility. The pricing exclusion point (EUR 150K+ Palantir pricing out 70,000 DACH companies) is sharp and specific.

### Slide 4: why-now — 100/100

**Suggestions:**
- Why-now slide is solid with four distinct catalysts. The EU AI Act August 2026 deadline is the strongest urgency driver and should be the lead bullet, not the second. The EUR 94B TAM figure appears here before the market sizing slide — creates slight redundancy. The Germany AI adoption near-doubling stat (20% → 36%) is a strong local proof point that deserves more prominence.

### Slide 5: solution — 100/100

**Suggestions:**
- Solution slide effectively leads with outcomes before architecture. The Stripe/SAP analogies are appropriate for the category creation narrative. The EUR 24K/year price anchor vs. EUR 80-150K self-build is compelling. However, 'Operations as a Service' is introduced here without sufficient definition — it appears again in slide 8 but the first mention needs a one-line definition to avoid confusion.

### Slide 6: product — 100/100

**Suggestions:**
- Product slide is technically strong but risks losing non-technical investors in the L1-L7 layer enumeration. The open/proprietary split is the key insight and should be the headline visual concept. The PII detection precision/recall target (>95%) is appropriately flagged as a target, not a measurement — good epistemic hygiene. Consider leading with the business outcome of each layer rather than the technical description.

### Slide 7: market-sizing — 97/100

**Suggestions:**
- Consider adding more metrics (4/5 present)
- Market sizing is the deck's most methodologically rigorous slide. Bottom-up DACH calculation is explicit and defensible. The EU-27 SAM claim (EUR 10B+) is asserted rather than derived — needs a one-line methodology (e.g., 'DACH SAM × EU-27/DACH GDP ratio'). The SOM Year 3 calculation (50 customers × EUR 60K ACV) is appropriately conservative and directly connected to existing pipeline.

### Slide 8: business-model — 84/100

**Issues:**
- Exceeds word limit: 139 words (max 130)

**Suggestions:**
- Consider adding more metrics (3/5 present)
- Business model slide is well-structured with the three-horizon gross margin trajectory. The Shopify analogy is apt. The land-and-expand mechanic (1 Plox → 4-6 Ploxes) is the NRR driver but lacks a timeline or measured expansion rate from existing clients. The 30% consulting margin claim needs a footnote or data room reference — it is a key input to the financial model and will be scrutinized.

### Slide 9: traction — 87/100

**Issues:**
- Exceeds word limit: 131 words (max 130)

**Suggestions:**
- Consider adding more metrics (4/5 present)
- Traction slide is the deck's strongest proof point. The EUR 170K/month revenue vs. EUR 80-100K cost framing is viscerally compelling. Named logos (Eventos, Falkensteg, Kalkül, Primus, Valor) add specificity. The NDR proxy methodology is transparently labeled as a proxy — intellectually honest. Weakness: no industry vertical breakdown of the 5 logos, which would help assess ICP concentration risk.

### Slide 10: go-to-market — 90/100

**Issues:**
- Exceeds word limit: 156 words (max 130)

**Suggestions:**
- GTM slide is logically structured across three phases. The AWS open-source playbook analogy is appropriate. Year 2 target (EUR 2.4M ARR, 40 customers) implies 4x growth from Year 1 (EUR 600K, 10 customers) — this growth rate is aggressive and should be justified with pipeline data or conversion rate assumptions. The channel partner model for EU-27 is plausible but no named partners or LOIs are mentioned.

### Slide 11: competitive-landscape — 100/100

**Suggestions:**
- Competitive landscape is above average. The two-axis framing (completeness vs. accessibility) is differentiated and defensible. The Langdock/Copilot complementary positioning is sophisticated. Critical gap: AWS Bedrock Agents, Azure AI Foundry, and Google Vertex AI Agent Builder are absent — these are the most credible competitive threats and their omission will be noticed by any technical investor. The moat description is strong but needs a 'why can't they copy this in 12 months' answer.

### Slide 12: team — 90/100

**Issues:**
- Exceeds word limit: 156 words (max 150)

**Suggestions:**
- Team slide is credible but the husband-wife founding team dynamic, while noted as capital-efficient, may raise governance questions from institutional investors — a brief note on board composition or independent oversight would preempt this. The Google Cloud advisory is genuinely valuable and well-positioned as a channel signal rather than a vanity board. The 4-5 engineer team size relative to the ambition described creates a credibility gap that the post-Seed hiring plan partially addresses.

### Slide 13: financials — 97/100

**Suggestions:**
- Consider adding more metrics (3/4 present)
- Financials slide is unusually strong for a pre-Seed deck. The 'Seed builds the product, not the company' reframe is memorable. The gross margin trajectory (30% → 70% → 80%+) is explicitly shown. The 20-24 month runway calculation is transparent. Weakness: the Year 2 EUR 2.4M ARR target (40 customers) implies signing ~30 new platform customers in 12 months with a team that has never done platform sales — the ramp assumption needs more support.

### Slide 14: the-ask — 100/100

**Suggestions:**
- Ask slide is well-structured with percentage breakdowns and milestone anchoring. The ZIM grant non-dilutive co-funding angle is a genuine differentiator and well-positioned. The Series A bridge (EUR 2M+ ARR → EUR 10-15M Series A) is appropriately framed as a target, not a commitment. Minor issue: EUR 360K labeled as 'ZIM grant co-funding contribution' is ambiguous — clarify whether this is the company's matching contribution to receive the grant or the grant itself.

### Slide 15: ai-architecture — 90/100

**Issues:**
- Exceeds word limit: 192 words (max 150)

**Suggestions:**
- AI architecture slide is technically impressive and clearly written for Dr. Andre Retterath specifically — the HiveMQ playbook reference is a deliberate alignment signal. However, its placement after the ask is structurally problematic: it deflates the closing momentum and reads as an afterthought despite containing the deck's strongest technical IP claims. The patent filing intent for agent-centric governance is important but flagged as 'planned' — this needs to be filed before the Seed closes to be a credible moat claim. Recommend moving to appendix or repositioning before the ask.

---

## Top Strengths

1. Exceptional capital efficiency proof: EUR 2M bootstrapped revenue with near-zero burn multiple is a top-decile signal for a pre-Seed company — the 'Seed builds the product, not the company' narrative is genuinely differentiated and directly addresses Earlybird's capital efficiency thesis with hard evidence rather than projections.
2. Practitioner-to-product origin story with quantified validation: The 25+ deployment foundation is not just a credibility claim — it is operationalized into specific measurements (60% → <30% infrastructure cost, 3-6 months → <6 weeks deployment) that make the product thesis empirically grounded rather than hypothetical, directly satisfying Earlybird's requirement for named customer evidence with quantified ROI.
3. Comprehensive Earlybird thesis coverage with deliberate alignment signals: The deck addresses all seven Earlybird thesis points, includes all required metrics categories, passes all seven VC custom checks, and contains specific portfolio references (HiveMQ OSS playbook, remberg category creation) that demonstrate genuine research into the investor's mental model — the technical architecture slide is explicitly written for Dr. Andre Retterath's known focus areas.

## Critical Gaps

1. Hard NDR metric is absent and the proxy is insufficient: '100% of pilots from existing clients' is a pipeline quality metric, not a retention metric. Earlybird explicitly lists NDR as a key metric. Even a rough estimate (e.g., 'all 5 accounts have expanded scope YoY, implying >120% NDR equivalent') would be more defensible than the current proxy — this gap will be the first question in any partner meeting.
2. Hyperscaler competitive threat is unaddressed: AWS Bedrock Agents, Azure AI Foundry, and Google Vertex AI Agent Builder are actively targeting the mid-market orchestration layer with aggressive pricing and native cloud integration advantages. Their absence from the competitive landscape slide is a significant credibility gap — a sophisticated investor will raise this immediately, and the deck has no prepared answer. This is the single most dangerous omission.
3. Global ambition is understaffed and the scaling logic is unproven: The deck maps a DACH → EU-27 → global trajectory with a 4-5 engineer team and no named channel partners, no signed reseller agreements, and no marketplace supply-side commitments. The Year 2 target of 40 platform customers (4x growth) with a first-time sales hire is aggressive without pipeline data to support it. The gap between the ambition of the narrative and the organizational capacity shown creates a credibility tension that the ask slide does not fully resolve.

## Improvement Priorities (ordered by impact)

1. Hard NDR metric is absent and the proxy is insufficient: '100% of pilots from existing clients' is a pipeline quality metric, not a retention metric. Earlybird explicitly lists NDR as a key metric. Even a rough estimate (e.g., 'all 5 accounts have expanded scope YoY, implying >120% NDR equivalent') would be more defensible than the current proxy — this gap will be the first question in any partner meeting.
2. Hyperscaler competitive threat is unaddressed: AWS Bedrock Agents, Azure AI Foundry, and Google Vertex AI Agent Builder are actively targeting the mid-market orchestration layer with aggressive pricing and native cloud integration advantages. Their absence from the competitive landscape slide is a significant credibility gap — a sophisticated investor will raise this immediately, and the deck has no prepared answer. This is the single most dangerous omission.
3. Global ambition is understaffed and the scaling logic is unproven: The deck maps a DACH → EU-27 → global trajectory with a 4-5 engineer team and no named channel partners, no signed reseller agreements, and no marketplace supply-side commitments. The Year 2 target of 40 platform customers (4x growth) with a first-time sales hire is aggressive without pipeline data to support it. The gap between the ambition of the narrative and the organizational capacity shown creates a credibility tension that the ask slide does not fully resolve.
4. Fix slide 8 (business-model): Exceeds word limit: 139 words (max 130)
5. Fix slide 9 (traction): Exceeds word limit: 131 words (max 130)
6. Fix slide 10 (go-to-market): Exceeds word limit: 156 words (max 130)

---

## Recommendation

NeuraPlox presents one of the stronger pre-Seed decks in the enterprise AI infrastructure category — the bootstrapped EUR 2M revenue, near-zero burn multiple, and practitioner-validated product thesis are genuinely differentiated signals that align well with Earlybird's capital efficiency and domain expertise theses. To move from a strong candidate to an exceptional one, three targeted revisions are required before submission: first, replace the NDR proxy with a calculated retention estimate using ACV expansion data from the 5 named accounts, even if approximate; second, add a dedicated competitive response to AWS Bedrock Agents and Azure AI Foundry with a specific 'why we win against hyperscalers in mid-market' argument — this is the question that will dominate the partner meeting; third, restructure the deck's closing sequence by moving the AI architecture slide (15) to an appendix and ending on the ask slide (14) with a crisp one-slide summary of the investment thesis, which will leave the room with the right final impression. The European sovereignty angle should also be elevated from a feature to a strategic identity in the competitive landscape slide, given Earlybird's Aleph Alpha investment and explicit sovereignty thesis — framing NeuraPlox as 'the Agent OS that keeps European enterprise AI in European hands' would resonate more directly with this specific investor's worldview and portfolio narrative.
